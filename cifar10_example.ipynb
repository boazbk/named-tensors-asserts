{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhwK2e16Id3x"
      },
      "source": [
        "# Assertions about named dimensions in pytorch\n",
        "\n",
        "[Open this in colab](https://githubtocolab.com/boazbk/named-tensors-asserts/blob/main/cifar10_example.ipynb)\n",
        "\n",
        "This is a demonstration of a small library to make assertions about tensor and model dimensions in pytorch\n",
        "\n",
        "__General idea:__\n",
        "We write: \n",
        "```python\n",
        "T &nt // \"batch=1024, channels=3, height=32, width=32\" \n",
        "```\n",
        "\n",
        "to assert that `T`'s shape is `(1024,3,32,32)` and to update the global\n",
        "named dimensions batch, channels,height, width to these values.\n",
        "\n",
        "We can access these with nt.batch, nt.width etc\n",
        "In future declarations we can write expressions such as: \n",
        "```python\n",
        "Q &nt // \"batch, channels*(height+1), width\"\n",
        "```\n",
        "\n",
        "To say that a model maps tensors with dimensions `['batch','width','height','channels']` to tensors with dimensions `['batch','output']`\n",
        "\n",
        "We we write: \n",
        "\n",
        "```python\n",
        "model &nt // \"batch, width, height, channels -> batch, output\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgaFAm8yInt2",
        "outputId": "1d5a9b36-a83e-4d58-aa6a-d4a7ec650084"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--2022-03-16 13:00:55--  https://raw.githubusercontent.com/boazbk/named-tensors-asserts/main/named_asserts.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15526 (15K) [text/plain]\n",
            "Saving to: 'named_asserts.py'\n",
            "\n",
            "     0K .......... .....                                      100% 9.14M=0.002s\n",
            "\n",
            "2022-03-16 13:00:56 (9.14 MB/s) - 'named_asserts.py' saved [15526/15526]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Uncomment for colab\n",
        "!wget https://raw.githubusercontent.com/boazbk/named-tensors-asserts/main/named_asserts.py -O named_asserts.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUTnmz0VIz7g",
        "outputId": "8a2779ba-e9c9-4030-ee96-87159ef61c70"
      },
      "outputs": [],
      "source": [
        "%run named_asserts.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dTrlk0NIUL2"
      },
      "source": [
        "We use the Pytorch CIFAR-10 tutorial as our example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4ahUx3W2IUL-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "eef24ec34e3f41ec9de5b7bc529abe47",
            "dc7d228c0c8c4c80b895cadd8b85fb42",
            "02d8b463e4464163b0f9c5bf503ff1ba",
            "b8ce7706ddf046a4ba40b06a57876372",
            "547da92328be416a90e44b670ea4e9a6",
            "6aa4cd7e87c740de917ec2c2b27c9922",
            "d82e7878edae4da393f3fb0a24ebcd85",
            "c50b5c18bc7d40788dc7aab3fcf9c7a5",
            "a40de12592ee40158d662f1dc4e18087",
            "6a23c452aa274c63b52ad0713eb077af",
            "39a0b5e6aa334fa9b8a7471b39a40081"
          ]
        },
        "id": "TzkQ7OY_IUMD",
        "outputId": "6b33e0b5-93be-40b3-e51d-086df58a9428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "#hack https://github.com/pytorch/vision/issues/5039\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jawf4wBiIUMF"
      },
      "source": [
        "Let us show some of the training images, for fun.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "DEEBgiAUIUMH",
        "outputId": "555e2ad0-fa26-491f-dfb6-e87b0e507ad7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frog  ship  plane cat  \n"
          ]
        }
      ],
      "source": [
        "# show images\n",
        "#imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'batch': 4, 'channels': 3, 'height': 32, 'width': 32}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "images &nt // \"(batch=4, channels=3, height=32, width =32)\"\n",
        "nt.dims"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX7Sjv5WIUMK"
      },
      "source": [
        ":2. Define a Convolutional Neural Network\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "Copy the neural network from the Neural Networks section before and modify it to\n",
        "take 3-channel images (instead of 1-channel images as it was defined).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0_gfPYVCIUMM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Updating channel1 to 6\n",
            "Updating conv1h to 28\n",
            "Updating conv1w to 28\n",
            "Updating pool1h to 14\n",
            "Updating pool1w to 14\n",
            "Updating channel2 to 16\n",
            "Updating conv2h to 10\n",
            "Updating conv2w to 10\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'batch': 4,\n",
              " 'channels': 3,\n",
              " 'height': 32,\n",
              " 'width': 32,\n",
              " 'channel1': 6,\n",
              " 'conv1h': 28,\n",
              " 'conv1w': 28,\n",
              " 'pool1h': 14,\n",
              " 'pool1w': 14,\n",
              " 'channel2': 16,\n",
              " 'conv2h': 10,\n",
              " 'conv2w': 10,\n",
              " 'pool2h': 5,\n",
              " 'pool2w': 5}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#From https://discuss.pytorch.org/t/utility-function-for-calculating-the-shape-of-a-conv-output/11173/5\n",
        "def conv_output_shape(h_,w_, kernel_size=1, stride=1, pad=0, dilation=1):\n",
        "    from math import floor\n",
        "    if type(kernel_size) is not tuple:\n",
        "        kernel_size = (kernel_size, kernel_size)\n",
        "    h = floor( ((h_ + (2 * pad) - ( dilation * (kernel_size[0] - 1) ) - 1 )/ stride) + 1)\n",
        "    w = floor( ((w_ + (2 * pad) - ( dilation * (kernel_size[1] - 1) ) - 1 )/ stride) + 1)\n",
        "    return h, w\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        a,b = conv_output_shape(nt.height,nt.width,5)\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5) &nt // \"batch,channels,width,height -> batch, channel1=6 ,conv1h=a, conv1w=b\"\n",
        "        poolh,poolw = conv_output_shape(nt.conv1h,nt.conv1w,2,2)\n",
        "        self.pool = nn.MaxPool2d(2, 2) &nt // \"batch, channel1, conv1h,conv1w -> batch, channel1,pool1h=poolh,pool1w=poolw\"\n",
        "        \n",
        "        a,b = conv_output_shape(nt.pool1h,nt.pool1w,5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5) &nt // \"batch, channel1, poolh,poolw -> batch, channel2=16, conv2h = a, conv2w=b\"\n",
        "        nt.pool2h,nt.pool2w = conv_output_shape(nt.conv2h,nt.conv2w,2,2)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  &nt // \"batch, channel2*pool2h*pool2w -> batch, 120\"\n",
        "        self.fc2 = nn.Linear(120, 84) &nt // \"batch, 120 -> batch, 84\"\n",
        "        self.fc3 = nn.Linear(84, 10) &nt // \"batch, 84 -> batch, 10\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        x &nt // \"batch, channels, height, width\"\n",
        "        x = self.pool(F.relu(self.conv1(x))) &nt // \"batch, channel1,pool1h,pool1w\" \n",
        "        x = self.pool(F.relu(self.conv2(x))) &nt // \"batch, channel2,pool2h,pool2w\"\n",
        "        x = torch.flatten(x, 1) &nt // \"batch, channel2*pool2h*pool2w\" # flatten all dimensions except batch \n",
        "        x = F.relu(self.fc1(x)) &nt // \"batch, 120\"\n",
        "        x = F.relu(self.fc2(x)) &nt // \"batch, 84\"\n",
        "        x = self.fc3(x) &nt // \"batch, 10\"\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net(images)\n",
        "nt.dims"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can supress the assertions by using `with skip_asserts():` in the code. We can also use `with skip_asserts(flag)` to skip the assertions if and only if the `flag` is True."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.randn(1, 3, 32, 32)\n",
        "with skip_asserts():\n",
        "    x &nt // \"batch, channels, height, width+1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimension expression batch, channels, height, width+1 must have the same dimensions as the tensor ([[[[ 1.4626, -1.5704, -0.55.., got (4, 3, 32, 33) vs torch.Size([1, 3, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    x &nt // \"batch, channels, height, width+1\"\n",
        "except AssertionError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXz-z_UCIUMN"
      },
      "source": [
        "#### Training   \n",
        "\n",
        "For fun we can also train the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "h8138LRdIUMO"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train(net):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "    for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "net1 , net2 = Net(), Net()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's train with and without assertions to see the difference (this is on a CPU in a  rather overloaded laptop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.174\n",
            "[1,  4000] loss: 1.861\n",
            "[1,  6000] loss: 1.695\n",
            "[1,  8000] loss: 1.601\n",
            "[1, 10000] loss: 1.523\n",
            "[1, 12000] loss: 1.491\n",
            "[2,  2000] loss: 1.428\n",
            "[2,  4000] loss: 1.386\n",
            "[2,  6000] loss: 1.372\n",
            "[2,  8000] loss: 1.325\n",
            "[2, 10000] loss: 1.323\n",
            "[2, 12000] loss: 1.287\n",
            "Finished Training\n",
            "Wall time: 5min 35s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "train(net1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.188\n",
            "[1,  4000] loss: 1.884\n",
            "[1,  6000] loss: 1.663\n",
            "[1,  8000] loss: 1.578\n",
            "[1, 10000] loss: 1.521\n",
            "[1, 12000] loss: 1.478\n",
            "[2,  2000] loss: 1.408\n",
            "[2,  4000] loss: 1.370\n",
            "[2,  6000] loss: 1.340\n",
            "[2,  8000] loss: 1.301\n",
            "[2, 10000] loss: 1.297\n",
            "[2, 12000] loss: 1.281\n",
            "Finished Training\n",
            "Wall time: 4min 39s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "with skip_asserts():\n",
        "    train(net2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DncH4YkEIUMT"
      },
      "source": [
        "### Testing\n",
        "\n",
        "For fun we can also test the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10-MKUXrIUMU"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk-OTLbNIUMW"
      },
      "source": [
        "Okay, now let us see what the neural network thinks these examples above are:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa8vUNnEIUMY"
      },
      "outputs": [],
      "source": [
        "outputs = net(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
        "                              for j in range(4)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "cifar10_named_asserts.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02d8b463e4464163b0f9c5bf503ff1ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c50b5c18bc7d40788dc7aab3fcf9c7a5",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a40de12592ee40158d662f1dc4e18087",
            "value": 170498071
          }
        },
        "39a0b5e6aa334fa9b8a7471b39a40081": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "547da92328be416a90e44b670ea4e9a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a23c452aa274c63b52ad0713eb077af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aa4cd7e87c740de917ec2c2b27c9922": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a40de12592ee40158d662f1dc4e18087": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8ce7706ddf046a4ba40b06a57876372": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a23c452aa274c63b52ad0713eb077af",
            "placeholder": "​",
            "style": "IPY_MODEL_39a0b5e6aa334fa9b8a7471b39a40081",
            "value": " 170499072/? [00:02&lt;00:00, 84601401.85it/s]"
          }
        },
        "c50b5c18bc7d40788dc7aab3fcf9c7a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d82e7878edae4da393f3fb0a24ebcd85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc7d228c0c8c4c80b895cadd8b85fb42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aa4cd7e87c740de917ec2c2b27c9922",
            "placeholder": "​",
            "style": "IPY_MODEL_d82e7878edae4da393f3fb0a24ebcd85",
            "value": ""
          }
        },
        "eef24ec34e3f41ec9de5b7bc529abe47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc7d228c0c8c4c80b895cadd8b85fb42",
              "IPY_MODEL_02d8b463e4464163b0f9c5bf503ff1ba",
              "IPY_MODEL_b8ce7706ddf046a4ba40b06a57876372"
            ],
            "layout": "IPY_MODEL_547da92328be416a90e44b670ea4e9a6"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
